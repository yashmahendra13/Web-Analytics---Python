{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Sentiment Mining </center>\n",
    "\n",
    "References:\n",
    "* http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx\n",
    "* https://pythonprogramming.net/twitter-sentiment-analysis-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Sentiment Mining ?\n",
    "* a.k.a Opinion extraction, Opionion mining, Sentiment analysis, Subjectivity analysis\n",
    "<img src=\"what_is_sentiment_mining.png\" width='70%'>\n",
    "<img src=\"what_is_sentiment_mining2.png\" width='70%'>\n",
    "source: http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why sentiment mining\n",
    "* Movie:  is this review positive or negative?\n",
    "* Products: what do people think about the new iPhone?\n",
    "* Public sentiment: how is consumer confidence? Is despair increasing?\n",
    "* Politics: what do people think about this candidate or issue?\n",
    "* Prediction: predict election outcomes or market trends from sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Objectives of Sentiment Mining\n",
    "* Detecting attitudes: “enduring, affectively colored beliefs, dispositions towards objects or persons”\n",
    "  * Holder (**object**) of attitude\n",
    "  * Target (**aspect/feature**) of attitude\n",
    "  * Type of attitude\n",
    "    * **positive** or **negative**\n",
    "    * **Scale of the attitute**, e.g. [1, 5], [strongly agree, agree, neutral, disagree, strongly disagree]\n",
    "* Example: The picture quality of this camera is amazing\n",
    "  * Holder (object): camera\n",
    "  * Target (aspect/feature): picture quality\n",
    "  * Attitude: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment analysis tasks \n",
    "Giving a set of text (reviews, documents etc.):\n",
    "1. Identify objects of the sentiment analysis\n",
    "    * **Named entities**: company names, brands, proper names, hashtags etc\n",
    "    * Usually object names or synonyms are explicitly mentioned \n",
    "2. For each object, identify and extract object aspects/features that have been commented on in each review text\n",
    "    * **Explicit** features\n",
    "      * e.g. the **battery life** of this camera is too short\n",
    "    * **Implicit** features \n",
    "      * e.g. the camera is too large (implicit feature: **size**)\n",
    "3. Determine whether the sentiment on the features are positive, negative or neutral.\n",
    "4. Generate a summary of sentiment on each feature and on each object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Aspect/feature detection\n",
    "* **Explicit features/aspects**: typically can be extracted by keywords and synonyms\n",
    "  - Question: how to find synonyms?\n",
    "  - Challenge: it may be difficult to find an exhaustive list of synonyms for an aspect\n",
    "  - e.g. <img src=\"hotel_feature.png\" width='50%'> Source: Lappas, T., Sabnis, G., & Valkanas, G. (2016). The <a href=https://www.researchgate.net/publication/309875086_The_Impact_of_Fake_Reviews_on_Online_Visibility_A_Vulnerability_Assessment_of_the_Hotel_Industry> impact of fake reviews on online visibility: A vulnerability assessment of the hotel industry</a>. Information Systems Research, 27(4), 940-961.  \n",
    "  \n",
    "* However, **implicit features**: may need a **supervised approach** (e.g. the camera is too large)\n",
    "  - Naive bayes, SVM, CNN with word embedding are perhaps good approaches here\n",
    "    - single-label or multi-label classification?\n",
    "  - Process:\n",
    "    - Select a set of documents with features/aspects both explicitly/implicitly mentioned\n",
    "    - Label each of the documents with features/aspects as classes\n",
    "    - Train a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Sentiment Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Challenges of sentiment analysis\n",
    "* Negation: \n",
    "  * e.g., This film should be <font color='blue'>brilliant</font>.  It sounds like a <font color='blue'>great</font> plot, the actors are <font color='blue'>first grade</font>, and the supporting cast is <font color='blue'>good</font> as well, and Stallone is attempting to deliver a good performance. However, it <font color='red'>can’t hold up</font>.\n",
    "* Language sublety: \n",
    "  * e.g. This is the kind of movie you go because the theater has air-conditioning\n",
    "* Domain Dependency\n",
    "  * e.g. unpredictable movie vs. unpredictable steering (car domain)\n",
    "* Lots of emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Unsupervised Sentiment Analysis \n",
    "* Lexicon-based method where sentiment is determined based on **opinion words** (e.g. “amazing”, “great”, “poor”) counted near features/aspects. \n",
    "    - Some useful rules:\n",
    "      - **Negative** sentiment:\n",
    "        - negative words not preceded by a negation within $n$ (e.g. three) words in the same sentence. \n",
    "        - positive words preceded by a negation within $n$ (e.g. three) words in the same sentence.\n",
    "      - **Positive** sentiment (in the similar fashion):\n",
    "        - positive words not preceded by a negation within $n$ (e.g. three) words in the same sentence. \n",
    "        - negative terms following a negation within $n$ (e.g. three) words in the same sentence\n",
    "* **Polarity**-based (Postive or Negative) approaches:\n",
    "    - <a href=\"https://www3.nd.edu/~mcdonald/Word_Lists.html\"> WordStat sentiment Dictionary</a>: This is probably one of the largest lexicons freely available. It contains ~14.000 words ( 9164 negative and 4847 positive words ) and gives words a binary classification (positive or a negative ) score.\n",
    "    - <a href=\"http://sentiwordnet.isti.cnr.it\"> SentiWordNet</a>; gives the words a positive or negative score between 0 and 1. It contains about 117.660 words, however only ~29.000 of these words have been scored (either positive or negative).\n",
    "    - LIWC (Linguistic Inquiry and Word Count)(http://www.liwc.net/)\n",
    "    - Turney Algorithm (<a href=\"https://arxiv.org/abs/cs/0212032\"> Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews</a>)\n",
    "      1. extract phrases, \n",
    "      2. detect sentiment of phrases\n",
    "         - Use search engine queries to check with cooccurrence of a phrase (e.g. low fees) with \"excellence\"/\"poor\" (Pointwise Mutual Inforamtion)\n",
    "      3. and average the sentiments\n",
    "* **Valence**-based where the **intensity** of the sentiment is considered, e.g. excellent, good, average\n",
    "     - VADER: <a href=\"http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf\"> A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. VADER \n",
    "- The method of VADER:\n",
    "    1. Created lexicons of sentiment-related words (~9000)\n",
    "      -  Built based on existing well-established sentiment word-banks (e.g. LIWC). \n",
    "      - Incorporated many lexical features \n",
    "        - Western-style emoticons10 (for example, \":-\")\n",
    "        - Sentiment-related acronyms (e.g., LOL) and  commonly used slangs with sentiment value (e.g., \"nah\", \"meh\" and \"giggly\"). \n",
    "    2. Rated sentiment-related words were manually rated in terms of sentiment intensity through Amazon Mechancical Turk: positive or negative (and optionally, to what degree)\n",
    "    3. Implemented heurestics rules:\n",
    "        - **Punctuation exclamation mark(!)** increases sentiment intensity, e.g. *\"The food here is good!!!\"*\n",
    "        - **Capitalization, specifically ALL-CAPS** of a sentiment-relevant word increases the sentiment intensity, e.g. *\"The food here is GREAT!\"*\n",
    "        - **Degree modifiers** (also called intensifiers, e.g. extremely) increases intensity\n",
    "        - **Contrastive conjunction \"but\"** signals a shift in sentiment polarity, with the sentiment of the text following the conjunction being dominant. e.g. *\"The food here is great, but the service is horrible\"*. \n",
    "\n",
    "- VADER analyzes a piece of text to see if any of the words in the text is present in the lexicon. Sentiment metrics are derived from the ratings of such words\n",
    "    - **Positive**, **neutral** and **negative**, represent the proportion of the text that falls into those categories. \n",
    "    - The final metric, the compound score, is the sum of all of the lexicon ratings which have been standardized to range between -1 and 1 based on some heuristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.1. SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "text='The food is good and the atmosphere is nice'\n",
    "ss = sid.polarity_scores(text)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2. Easy sentences\n",
    "\n",
    "#http://www.nltk.org/howto/sentiment.html\n",
    "#http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html\n",
    "#https://www.researchgate.net/publication/275828927_VADER_A_Parsimonious_Rule-based_Model_for_Sentiment_Analysis_of_Social_Media_Text\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "sentences = [\"VADER is smart, handsome, and funny.\", # positive sentence example\n",
    " \"VADER is smart, handsome, and funny!\", # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    " \"VADER is very smart, handsome, and funny.\",  # booster words handled correctly (sentiment intensity adjusted)\n",
    " \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
    " \"VADER is VERY SMART, handsome, and FUNNY!!!\",# combination of signals - VADER appropriately adjusts intensity\n",
    " \"VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\",# booster words & punctuation make this close to ceiling for score\n",
    " \"The book was good.\",         # positive sentence\n",
    " \"The book was kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n",
    " \"The plot was good, but the characters \\\n",
    " are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
    " \"A really bad, horrible book.\",       # negative sentence with booster words\n",
    " \"At least it isn't a horrible book.\", # negated negative sentence with contraction\n",
    " \":) and :D\"     # emoticons handled\n",
    " ]\n",
    "\n",
    "# initalize analyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.3. Tricky sentences\n",
    "# How do you think the performance of VADER\n",
    "# for this group of sentences?\n",
    "\n",
    "tricky_sentences = [\n",
    "    \"Sentiment analysis has never been good.\",\n",
    "    \"Sentiment analysis with VADER has never been this good.\",\n",
    "    \"Warren Beatty has never been so entertaining.\",\n",
    "    \"I won't say that the movie is astounding and I wouldn't claim that \"]\n",
    "\n",
    "# initalize analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in tricky_sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.4. Tricky Paragraph\n",
    "\n",
    "# Deal with Paragraph\n",
    "# question: if a paragraph contains mixed positive and \n",
    "# negative sentences, how do you determine the sentiment\n",
    "# of the entire paragraph?\n",
    "\n",
    "paragraph = \"This film should be brilliant. \\\n",
    "             It sounds like a great plot, the actors are first grade, \\\n",
    "             and the supporting cast is good as well, \\\n",
    "             and Stallone is attempting to deliver a good performance. \\\n",
    "             However, it can’t hold up.\"\n",
    "\n",
    "# split into sentences\n",
    "lines_list = tokenize.sent_tokenize(paragraph)\n",
    "\n",
    "# initalize analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# analyze the sentiment sentence by sentence\n",
    "\n",
    "for sentence in lines_list:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# what if you analyze the entire sentence as a whole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 4.5. Design a document sentiment classifier based on VADER\n",
    "# test your classifier using amazon review dataset\n",
    "# and estimate its accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Supervised Sentiment Analysis\n",
    "- Naive Bayes (Base line), SVM, CNN. \n",
    "- Different ways to generate feature space:\n",
    "  * TF-IDF with all tokens\n",
    "  * with binary counts only\n",
    "  * Word embedding\n",
    "- Check lecture notes for \"Text Classification\" and \"Deep Learning II\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
