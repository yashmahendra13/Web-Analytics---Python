{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping</center>\n",
    "\n",
    "References: \n",
    " - https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    " - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Different ways to access data on the web\n",
    " - Scrape HTML web pages \n",
    " - Download data file directly \n",
    "    * data files such as csv, txt\n",
    "    * pdf files\n",
    " - Access data through Application Programming Interface (API), e.g. The Movie DB, Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scape HTML web pages using BeatifulSoup\n",
    "\n",
    "### 2.1. Basic structure of HTML pages###\n",
    "* HTML tages: <font color=\"green\">head</font>, <font color=\"green\">body</font>, <font color=\"green\">p</font>, <font color=\"green\">a</font>, <font color=\"green\">form</font>, <font color=\"green\">table </font>, ...\n",
    "* A tag may have properties. \n",
    "  * For example, tag <font color=\"green\">a</font> has property (or attribute) <font color=\"green\">href</font>, the target of the link\n",
    "  *  <font color=\"green\">class</font> and <font color=\"green\">id</font> are special properties used by html to control the style of each element through Cascading Style Sheets (CSS). <font color=\"green\">id</font> is the unique identifier of an element, and <font color=\"green\">class</font> is used to group elements for styling. \n",
    "* A tag can be referenced by its position in relation to each other \n",
    "  * **child** – a child is a tag inside another tag, e.g. the two <font color=\"green\">p</font> tags are children of the <font color=\"green\">div</font> tag.\n",
    "  * **parent** – a parent is the tag another tag is inside, e.g. the <font color=\"green\">html</font> tag is the parent of the <font color=\"green\">body</font> tag.\n",
    "  * **sibling** – a sibling is a tag that has the same parent as another tag, e.g. in the html example, the <font color=\"green\">head</font> and <font color=\"green\">body</font> tags are siblings, since they’re both inside <font color=\"green\">html</font>. Both <font color=\"green\">p</font> tags are siblings, since they’re both inside <font color=\"green\">body</font>."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample html source code (http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html):\n",
    "-----------------------\n",
    " \n",
    " <html>\n",
    "    <head>\n",
    "        <title>A simple example page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <p class=\"inner-text first-item\" id=\"first\">\n",
    "                First paragraph.\n",
    "            </p>\n",
    "            <p class=\"inner-text\">\n",
    "                Second paragraph.\n",
    "            </p>\n",
    "        </div>\n",
    "        <p class=\"outer-text first-item\" id=\"second\">\n",
    "            <b>\n",
    "                First outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "        <p class=\"outer-text\">\n",
    "            <b>\n",
    "                Second outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web page displayed:\n",
    "--------------------\n",
    "\n",
    "First paragraph.\n",
    "\n",
    "Second paragraph.\n",
    "\n",
    "**First outer paragraph.**\n",
    "\n",
    "**Second outer paragraph. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Basic steps of scraping a web page using package BeautifulSoup ###\n",
    "  1. Install modules <font color=\"green\">requests</font>, <font color=\"green\">BeautifulSoup4</font>.\n",
    "      * **requests**: allow you to send HTTP/1.1 requests using Python. To install:\n",
    "          - Open terminal (Mac) or Anaconda Command Prompt (Windows)\n",
    "          - Issue: pip install requests\n",
    "      * **BeautifulSoup**: web page parsing library, to install, use: pip install beautifulsoup4\n",
    "  1. Open the **source code of the web page** to find out html elements that you will scrape\n",
    "      * Firefox: right click on the web page and select \"view page source\"\n",
    "      * Safari: please instruction here to see page source (http://ccm.net/faq/33026-safari-view-the-source-code-of-a-webpage)\n",
    "      * Ineternet Explorer: see instruction at https://www.computerhope.com/issues/ch000746.htm\n",
    "  2. Use <font color=\"green\">**request**</font> library to retrive the source code\n",
    "  3. Use libraries to parse the source code. Available libraries:\n",
    "      * <font color=\"green\">Beautifulsoup</font>\n",
    "      * <font color=\"green\">lxml</font>: another good library for web page scraping\n",
    "      * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Scrape the sample html using BeautifulSoup ###\n",
    "- Kinds of Objects in BeautifulSoup\n",
    "  * <font color=\"green\">**Tag**</font>: an xml or HTML tag\n",
    "  * <font color=\"green\">**Name**</font>: every tag has a name\n",
    "  * <font color=\"green\">**Attributes**</font>: a tag may have any number of attributes. A tag is shown as a **dictionary** in the form of {attribute1_name:attribute1_value, attribute2_name:attribute2_value, ...}. If an attribute has multiple values, the value is stored as a list\n",
    "  * <font color=\"green\">**NavigableString**</font>: the text within a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.1. Import requests and beautifulsoup packages\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# import requests package\n",
    "import requests                   \n",
    "\n",
    "# import BeautifulSoup from package bs4 (i.e. beautifulsoup4)\n",
    "from bs4 import BeautifulSoup     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3.2. Get web page content\n",
    "\n",
    "# send a get request to the web page\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")    \n",
    "\n",
    "# status_code 200 indicates success. \n",
    "# a status code >200 indicates a failure\n",
    "if page.status_code==200:   \n",
    "    \n",
    "    # content property gives the content returned in bytes \n",
    "    print(page.content)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basics of HTTP (Hypertext Transfer Protocol)**\n",
    "- HTTP is designed to enable communications between clients (e.g. browser) and servers (e.g. Apache web server).\n",
    "- A client submits an HTTP **request** to the server; then the server returns a **response** to the client. \n",
    "- Two commonly used methods for a request-response between a client and server:\n",
    "  - GET - Requests data from a specified resource\n",
    "  - POST - Submits data to be processed to a specified resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.3. Parse web page content\n",
    "\n",
    "# Process the returned content using beautifulsoup module\n",
    "\n",
    "# initiate a beautifulsoup object using the html source and Python’s html.parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')  \n",
    "\n",
    "# soup object stands for the **root** node of the html document tree\n",
    "print(\"Soup object:\")\n",
    "# print soup object nicely\n",
    "print(soup.prettify())                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.children returns an iterator of all children nodes\n",
    "print(\"\\soup children nodes:\")\n",
    "soup_children=soup.children\n",
    "print(soup_children)\n",
    "\n",
    "# convert to list\n",
    "soup_children=list(soup.children)\n",
    "print(\"\\nlist of children of root:\")\n",
    "print(len(soup_children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "# html is the only child of the root node\n",
    "html=soup_children[0]    \n",
    "\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3.4. Get head and body tag\n",
    "\n",
    "html_children=list(html.children)\n",
    "# head is the the 2nd child of html\n",
    "print(html_children)\n",
    "head=html_children[1]\n",
    "\n",
    "# extract all text inside head\n",
    "print(\"\\nhead text:\")\n",
    "print(head.get_text())\n",
    "\n",
    "# body is the fourth child of html\n",
    "body=html_children[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.5. Continue the navigation through html document tree \n",
    "\n",
    "# Task 1. get div tag inside body. \n",
    "# div is the second child of body\n",
    "\n",
    "\n",
    "# Task 2: get the first p in div (2nd child of div)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3.6. Get details of a tag\n",
    "\n",
    "# get the first p tag in the div of body\n",
    "div=list(body.children)[1]\n",
    "p=list(div.children)[1]\n",
    "\n",
    "p\n",
    "\n",
    "# get the details of p tag\n",
    "# first, get the data type of p\n",
    "print(\"\\ndata type:\")\n",
    "print(type(p))\n",
    "# get tag name (property of p object)\n",
    "print (\"\\ntag name: \")     \n",
    "print(p.name)\n",
    "\n",
    "# a tag object with attributes has a dictionary. \n",
    "# each attribute name of the tag is a key\n",
    "# get \"class\" attribute\n",
    "\n",
    "print (\"\\ntag class: \")\n",
    "print(p[\"class\"])\n",
    "\n",
    "# get text of p tag\n",
    "p.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Exercise 2.3.7.  get siblings of p object\n",
    "print(\"\\nget siblings of the first p tag\")\n",
    "print(list(p.next_siblings))\n",
    "\n",
    "# get next p tag within the div\n",
    "# get the sibling next to the next sibling of p\n",
    "print(\"\\nget the 2nd p tag\")\n",
    "print(p.next_sibling.next_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Navigating the html document tree ###\n",
    " \n",
    "* Going down\n",
    "  * <font color=\"green\">**contents**</font>: get a tag's direct children as a **list**\n",
    "  * <font color=\"green\">**children**</font>: get a tag's direct chidren as an **iterator**\n",
    "  * <font color=\"green\">**descendants**</font>:  get an iterator for a tag's all descendants, including direct children, the children of its direct children, and so on\n",
    "* Going up\n",
    "  * <font color=\"green\">**parent**</font>: get a tag's parent\n",
    "  * <font color=\"green\">**parents**</font>: get an iterator for a tag's ancestors, from the parent to the very top of the document\n",
    "* Going sideways\n",
    "  * <font color=\"green\">**next_sibling**</font>: get a tag's next sibling\n",
    "  * <font color=\"green\">**previous_sibling**</font>: get a tag's previous sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Finding all tags by filters and save found tags into a list ###\n",
    "* **find_all**: find **all instances of a tag** at once, e.g. find\\_all('p')\n",
    "* search for tags by **attributes**, e.g. find\\_all(<font color=\"blue\">**class\\_**</font> ='inner-text', id=\"first\")\n",
    "* search for tags by **tag names and attributes**, e.g. find\\_all('p', class\\_ ='inner-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.1. find all p tags\n",
    "\n",
    "# find all p tags\n",
    "for p in soup.find_all('p'):\n",
    "    print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.2.  Searching for tags by attributes\n",
    "# since \"class\" is reserved word, \n",
    "#\"class_\" is used to denote attribute \"class\"\n",
    "for p in soup.find_all(class_ ='inner-text', id=\"first\"):\n",
    "    print (p )                                \n",
    "    # note: p tag has two class values: inner-text and first-item. \n",
    "    # The filter matches with one of them\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.5.3. Searching for tags by names and attributes\n",
    "for p in soup.find_all(\"p\", class_ ='first-item', id='first'):\n",
    "    print (p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.5.4. Get the details of a tag\n",
    "\n",
    "# p is the object you found in Exercise 2.5.3\n",
    "\n",
    "# get data type of object p\n",
    "print(\"data type of object p\", type(p))\n",
    "\n",
    "# get tag name\n",
    "print(\"tag's name:\", p.name)\n",
    "\n",
    "# get attributes\n",
    "print(\"tag's class attribute:\", p[\"class\"])\n",
    "print(\"tag's id attribute:\", p[\"id\"])\n",
    "\n",
    "# get tag's text\n",
    "print(\"tag's text:\", p.get_text())\n",
    "\n",
    "# the tag's text is a NivagableString\n",
    "p_text=list(p.children)\n",
    "print(\"tag's text object data type:\", type(p_text[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.  Select tags into a list by CSS Selectors: select ###\n",
    "* CSS selectors used by CSS language to specify HTML tags to style\n",
    "* Some examples:\n",
    "  1. **div p** – finds all <font color=\"green\">p</font> tags inside a <font color=\"green\">div</font> tag.\n",
    "  2. **body p b** – finds all <font color=\"green\">b</font> tags inside a <font color=\"green\">p</font> tags within a <font color=\"green\">body</font> tag\n",
    "  3. **p.outer-text** – finds all <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text**.\n",
    "  4. **p#first** – finds all <font color=\"green\">p</font> tags with an <font color=\"green\">id</font> attribute of **first**\n",
    "  5. **p[class=outer-text]** – finds all <font color=\"green\">p</font> tags with a class attribute that is **exactly** \"outer-text\" (no other class). Note [ ] is the generic way to define a filter on any attribute. \".\" is just for \"class\" attribute.\n",
    "  6. **p[class~=outer-text]** – finds all <font color=\"green\">p</font> tags  with a class attribute that **contains** a value \"outer-text\" (it may contain other values too, equivalent to p.outer-text). \n",
    "  7. **body p.outer-text b** – finds any <font color=\"green\">b</font> tags within <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text** inside of a <font color=\"green\">body</font> tag.\n",
    "  8. **div, p** – finds all <font color=\"green\">div</font> and <font color=\"green\">p</font> tags (without nesting relationships). Compare it with example #1!\n",
    "  9. **p.outer-text.first-item** – finds all <font color=\"green\">p</font> tags  with **both class attribute \"outer-text\" and \"first-item\"**.\n",
    "  10. What about finding all p with class \"outer-text\" but not class \"first-item\"?\n",
    "        \n",
    "* For details of css selectors, see https://developer.mozilla.org/en-US/docs/Learn/CSS/Introduction_to_CSS/Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.1.: select p tags within div tags\n",
    "# Notice the space between div and p\n",
    "# This means p is a descendant of div \n",
    "# p is not necessarily a direct child of div\n",
    "soup.select(\"div p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.2.: select b tags within p tags in the body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.3.: finds all p tags with a class of outer-text\n",
    "soup.select(\"p.outer-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.4.: select p tags with id \"first\"\n",
    "soup.select(\"p#first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.5.:find p tag within body and\n",
    "# with a class attribute which is **exactly** \"outer-text\"\n",
    "\n",
    "# Note: this is the generic way to set  \n",
    "# a fileter on any attribute\n",
    "\n",
    "soup.select(\"body p[class=outer-text]\")\n",
    "# compare the result with # Exercise 2.6.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.6. find p tag with body \n",
    "# which has a class attribute **containing** a value \"out-text\"\n",
    "# Note the use of \"~\". \n",
    "\n",
    "soup.select(\"body p[class~=outer-text]\")\n",
    "\n",
    "# This is equivalent to soup.select(\"body p.outer-text\")\n",
    "# However, it's a generic way to set condition \n",
    "# on any type of attributes, not just \"class\" attribute\n",
    "\n",
    "soup.select(\"body p.outer-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.7. select b tags within \n",
    "# p tags which has a class outer-text and \n",
    "# is within the body tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.8. select all div and p tags \n",
    "# Compare the result with Exercise 2.6.1.\n",
    "# \",\" between tags means \"and/or\", \n",
    "# while \" \" (space) between tags means \"descendant\"\n",
    "soup.select(\"div, p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.6.9. select p tags \n",
    "# with two classes: outer-text and first-item\n",
    "soup.select(\"p.outer-text.first-item\")\n",
    "\n",
    "# what if another class, say \"xxx\" also required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.10. finding all p tags with class \"outer-text\" \n",
    "# but not class \"first-item\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.  Example: downloading weather forecast for the next week for New York City ###\n",
    "- Instruction:\n",
    "    1. Open web site http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU and inspect page source\n",
    "    2. Find \"Extended Forecast for\" in the source code\n",
    "    3. Extract div tags in this section using \"seven-day-forecast-body div ul li div.tombstone-container\"\n",
    "       * Notice that the div under \"Extended Forecast for\" is what we need\n",
    "       * Follow the path to weather forecast for each period\n",
    "       <img src='weather.png' width='60%'>\n",
    "    4. For each div tag, extract text in different p tags and represent the result as a tuple, e.g. (\"Today\", \"Mostly Sunny\", \"High: 75F\"). Save the 7-day forecast as a list and print the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.7.1. downloading weather forecast for the next week for New York City \n",
    "\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU\")    # send a get request to the web page\n",
    "rows=[]\n",
    "\n",
    "# status_code 200 indicates success. \n",
    "#a status code >200 indicates a failure \n",
    "if page.status_code==200:        \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # find a block with id='seven-day-forecast-body'\n",
    "    # follow the path down to the div for each period\n",
    "    divs=soup.select(\"div#seven-day-forecast-body \\\n",
    "    div ul li div.tombstone-container\")\n",
    "    #print len(divs)\n",
    "    #print divs\n",
    "    \n",
    "    for idx, div in enumerate(divs):\n",
    "        # for testing you can print idx, div\n",
    "        #print idx, div \n",
    "        \n",
    "        # initiate the variable for each period\n",
    "        title=None\n",
    "        desc=None\n",
    "        temp=None\n",
    "        \n",
    "        # get title\n",
    "        p_title=div.select(\"p.period-name\")\n",
    "        \n",
    "        # test if \"period-name\" indeed exists\n",
    "        # before you get the text\n",
    "        if p_title!=[]:\n",
    "            title=p_title[0].get_text()\n",
    "        \n",
    "        # get description\n",
    "        p_desc=div.select(\"p.short-desc\")\n",
    "        if p_desc!=[]:\n",
    "            desc=p_desc[0].get_text()\n",
    "        \n",
    "        # get temperature\n",
    "        p_temp=div.select(\"p.temp\")\n",
    "        if p_temp!=[]:\n",
    "            temp=p_temp[0].get_text()\n",
    "            \n",
    "        # add title, description, and temperature as a tuple into the list\n",
    "        rows.append((title, desc, temp))\n",
    "        print((title, desc, temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.7.2. Extract \"Detailed Forecast\" section in the web page "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
